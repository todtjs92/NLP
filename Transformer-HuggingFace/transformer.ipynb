{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"transformer.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","metadata":{"id":"iSjVs8WLygwX","executionInfo":{"status":"ok","timestamp":1660718315234,"user_tz":-540,"elapsed":2084,"user":{"displayName":"김정의","userId":"05657577236532280758"}}},"source":["import os\n","\n","# 수학 관련 라이브러리\n","import numpy as np\n","import math\n","# pytorch 관련 라이브러리\n","import torch\n","import torch.nn as nn \n","import torch.nn.functional as F "],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FOFFox88ygwX"},"source":["# sample input"]},{"cell_type":"code","metadata":{"id":"LXfXDvaRygwY","executionInfo":{"status":"ok","timestamp":1660718315234,"user_tz":-540,"elapsed":9,"user":{"displayName":"김정의","userId":"05657577236532280758"}}},"source":["sample_input = torch.tensor([[  101,  2572,  3217,  5831,  5496,  2010,  2567,  1010,  3183,  2002,\n","         2170,  1000,  1996,  7409,  1000,  1010,  1997,  9969,  4487, 23809,\n","         3436,  2010,  3350,  1012,   102,  7727,  2000,  2032,  2004,  2069,\n","         1000,  1996,  7409,  1000,  1010,  2572,  3217,  5831,  5496,  2010,\n","         2567,  1997,  9969,  4487, 23809,  3436,  2010,  3350,  1012,   102,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0]])\n","# 문장 1개에 패딩 붙은 형태\n","\n","\n","sample_label = torch.tensor([1])\n","\n","sample = [sample_input,sample_label]\n","\n","# label : 1 \n","# sentence 1 : Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.\n","# sentence 2 : Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\n","\n","\n","sample_config = {\n","    \"dim\": 768,\n","    \"dim_ff\": 3072,\n","    \"n_layers\": 12,\n","    \"p_drop_attn\": 0.1,\n","    \"n_heads\": 12,\n","    \"p_drop_hidden\": 0.1,\n","    \"max_len\": 512,\n","    \"n_segments\": 2,\n","    \"vocab_size\": 30522\n","}\n","\n","class AttributeDict(dict):\n","    def __getattr__(self, name):\n","        return self[name]\n","model_config = AttributeDict(sample_config)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nmnf_7LYygwZ","outputId":"166c0c16-8d75-48c2-8d29-2d4774496b41","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660718315234,"user_tz":-540,"elapsed":8,"user":{"displayName":"김정의","userId":"05657577236532280758"}}},"source":["sample_input.size()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 128])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"yiAuHp_aygwa"},"source":["# Activation function"]},{"cell_type":"code","metadata":{"id":"t5iaNO2Qygwa","executionInfo":{"status":"ok","timestamp":1660718315234,"user_tz":-540,"elapsed":7,"user":{"displayName":"김정의","userId":"05657577236532280758"}}},"source":["def gelu(x):\n","    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3b2rNAaQygwa"},"source":["# Layer normalization"]},{"cell_type":"code","source":["# layernorm이 토치에 구현되있음\n","# 이거 add+ norm부분에 들어가던거 "],"metadata":{"id":"cto02nhIh6Jy"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LGIsARItygwb","executionInfo":{"status":"ok","timestamp":1660718391119,"user_tz":-540,"elapsed":319,"user":{"displayName":"김정의","userId":"05657577236532280758"}}},"source":["class LayerNorm(nn.Module):\n","    def __init__(self, cfg, variance_epsilon=1e-12):\n","        super().__init__()\n","        self.gamma = nn.Parameter(torch.ones(cfg.dim))\n","        self.beta  = nn.Parameter(torch.zeros(cfg.dim))\n","        self.variance_epsilon = variance_epsilon\n","\n","    def forward(self, x):\n","        # get mean, variance\n","        u = x.mean(-1, keepdim=True) # sequence 방향 mean\n","        s = (x - u).pow(2).mean(-1, keepdim=True) # sequence 방향 variance\n","        \n","        # normalize\n","        x = (x - u) / torch.sqrt(s + self.variance_epsilon) # (x - mean)/std \n","        \n","        return self.gamma * x + self.beta # gamma, beta를 이용해 mean, std 조정"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Aq8hPlQ9ygwb"},"source":["# Embedding"]},{"cell_type":"code","metadata":{"id":"tWtg21x3ygwc","executionInfo":{"status":"ok","timestamp":1660718315235,"user_tz":-540,"elapsed":8,"user":{"displayName":"김정의","userId":"05657577236532280758"}}},"source":["# get_sinusoid_encoding = postional encoding \n","def get_sinusoid_encoding_table(n_position, d_model):\n","    def cal_angle(position, hid_idx):\n","        return position / np.power(10000, 2 * (hid_idx // 2) / d_model)\n","    def get_posi_angle_vec(position):\n","        return [cal_angle(position, hid_j) for hid_j in range(d_model)]\n","\n","    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(n_position)])\n","    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n","    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n","    return torch.FloatTensor(sinusoid_table)\n","\n","# word embeding부분인듯 \n","class Embeddings(nn.Module):\n","    \"The embedding module from word, position and token_type embeddings.\"\n","    def __init__(self, cfg):\n","        super().__init__()\n","        \n","        self.tok_embed = nn.Embedding(cfg.vocab_size, cfg.dim) # token embedding\n","        self.pos_embed = nn.Embedding.from_pretrained(get_sinusoid_encoding_table(cfg.max_len, cfg.dim),freeze=True) # position embedding\n","\n","        self.norm = LayerNorm(cfg)\n","        self.drop = nn.Dropout(cfg.p_drop_hidden)\n","\n","    def forward(self, x):\n","        seq_len = x.size(1)\n","        pos = torch.arange(seq_len, dtype=torch.long, device=x.device) # 0,1,2,3,4,5, ..., seq_len-1\n","        pos = pos.unsqueeze(0).expand_as(x) # (S,) -> (B, S)\n","\n","        e = self.tok_embed(x) + self.pos_embed(pos)\n","        return self.drop(self.norm(e))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"rzb7t4PBygwc","executionInfo":{"status":"ok","timestamp":1660718807392,"user_tz":-540,"elapsed":1459,"user":{"displayName":"김정의","userId":"05657577236532280758"}}},"source":["model = Embeddings(model_config)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"TRMUNZ1dygwd","outputId":"f1ba3a6c-8144-4b70-8d6a-87661c700bdd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660718807393,"user_tz":-540,"elapsed":5,"user":{"displayName":"김정의","userId":"05657577236532280758"}}},"source":["out = model(sample[0])\n","out.size()\n"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 128, 768])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"jhT3QmbKygwd","outputId":"f8e6de2e-850c-4bae-dfb7-73e7038baf8a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660718808851,"user_tz":-540,"elapsed":2,"user":{"displayName":"김정의","userId":"05657577236532280758"}}},"source":["out"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-1.1387, -0.5771,  0.2106,  ...,  0.0000, -0.5380,  0.0000],\n","         [ 0.8485,  0.9378,  0.5239,  ..., -0.6106, -2.1513,  0.8872],\n","         [ 1.8757, -0.4736, -0.0880,  ..., -0.9354, -0.9027,  0.4668],\n","         ...,\n","         [-1.4791,  0.8505, -0.1391,  ...,  0.1763,  1.2225,  1.2567],\n","         [-0.6083,  0.0000, -1.0105,  ...,  0.1768,  1.2280,  1.2622],\n","         [-0.0116,  0.3409, -1.5030,  ...,  0.1781,  1.2350,  1.2693]]],\n","       grad_fn=<MulBackward0>)"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"kJv4r1Ihygwe"},"source":["#  Transformer encoder"]},{"cell_type":"code","metadata":{"id":"7CsAx5beygwe"},"source":["class Attention(nn.Module): \n","    #Scaled Dot Product Attention\n","    \n","    def forward(self, query, key, value, mask=None, dropout=None):\n","        scores = torch.matmul(query, key.transpose(-2, -1)) \\\n","                 / math.sqrt(query.size(-1)) # scale\n","        print(mask.size(), scores.size())\n","        \n","        # 이부분까지 QK부분 \n","\n","        # q = [batch, sequence_length , hidden ]\n","        # k.T = [ batch , sequence_length, hidden ] 이런식으로 \n","        # matmul 이용해서 3차원 텐서 계산 가능함.  배치 각각에 대하여 matmul 연산 해주는 방법임.  \n","        \n","        if mask is not None:\n","          \n","            scores = scores.masked_fill(mask == 0, -1e9)\n","\n","        p_attn = F.softmax(scores, dim=-1)\n","\n","        if dropout is not None:\n","            p_attn = dropout(p_attn)\n","\n","        return torch.matmul(p_attn, value), p_attn # qkv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UrF_s93Iygwe"},"source":["def split_last(x, shape):                   # [B,S,D] 를 헤드 개수만큼 쪼개주는 함수 , [B,S,H,D/H]\n","    # [B,T,H] -> [B,T,H1,H2]\n","    \"split the last dimension to given shape\"\n","    shape = list(shape)\n","    assert shape.count(-1) <= 1\n","    if -1 in shape:\n","        shape[shape.index(-1)] = int(x.size(-1) / -np.prod(shape))\n","    return x.view(*x.size()[:-1], *shape)\n","\n","def merge_last(x, n_dims):\n","    \"merge the last n_dims to a dimension\"\n","    s = x.size()\n","    assert n_dims > 1 and n_dims < len(s)\n","    return x.view(*s[:-n_dims], -1)\n","\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\" Multi-Headed Dot Product Attention \"\"\"\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.proj_q = nn.Linear(cfg.dim, cfg.dim) # 워드 임베딩들어왔을떄 q,k, v 만들어주기 위한 웨이트 매트릭스 부분임 . \n","        self.proj_k = nn.Linear(cfg.dim, cfg.dim)\n","        self.proj_v = nn.Linear(cfg.dim, cfg.dim)\n","        self.drop = nn.Dropout(cfg.p_drop_attn)\n","        self.scores = None # for visualization\n","        self.n_heads = cfg.n_heads\n","\n","    def forward(self, x, mask, x_q=None):\n","        \"\"\"\n","        x, q(query), k(key), v(value) : (B(batch_size), S(seq_len), D(dim))\n","        mask : (B(batch_size) x S(seq_len))\n","        * split D(dim) into (H(n_heads), W(width of head)) ; D = H * W\n","        \"\"\"\n","        \n","        \n","        \n","        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n","        if x_q is None:\n","            q, k, v = self.proj_q(x), self.proj_k(x), self.proj_v(x) # 여기다가 정의를 해두었구나 , 인코더부분쓰느거랑 , 디코더의 인풋쓰는 부분. \n","        else: \n","            q, k, v = self.proj_q(x_q), self.proj_k(x), self.proj_v(x)\n","        q, k, v = (split_last(x, (self.n_heads, -1)).transpose(1, 2)        # [B,S,D] 를 [B,H, S, D/H] 로 바꿔주는 부분.  \n","                   for x in [q, k, v])\n","        # (B, H, S, W) @ (B, H, W, S) -> (B, H, S, S) -softmax-> (B, H, S, S) @ = torch. matmul\n","        scores = q @ k.transpose(-2, -1) / np.sqrt(k.size(-1)) # @ == torch.matmul (dot product)\n","        if mask is not None:\n","            mask = mask[:, None, :].float()\n","            scores -= 10000.0 * (1.0 - mask)\n","        scores = self.drop(F.softmax(scores, dim=-1))\n","        # (B, H, S, S) @ (B, H, S, W) -> (B, H, S, W) -trans-> (B, S, H, W)\n","        h = (scores @ v).transpose(1, 2).contiguous()\n","        # -merge-> (B, S, D)\n","        h = merge_last(h, 2) # 멀티헤드 어텐션으로 나눴던애들 다시 합쳐주는 부분.  \n","        self.scores = scores\n","        return h"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bR85zbXdygwf"},"source":["# Base feedforward network"]},{"cell_type":"code","metadata":{"id":"byqdScQoygwf","executionInfo":{"status":"ok","timestamp":1660720476950,"user_tz":-540,"elapsed":428,"user":{"displayName":"김정의","userId":"05657577236532280758"}}},"source":["class PositionWiseFeedForward(nn.Module):\n","    \"\"\" FeedForward Neural Networks for each position \"\"\"\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.fc1 = nn.Linear(cfg.dim, cfg.dim_ff)\n","        self.fc2 = nn.Linear(cfg.dim_ff, cfg.dim)\n","\n","    def forward(self, x):\n","        # (B, S, D) -> (B, S, D_ff) -> (B, S, D)\n","        return self.fc2(gelu(self.fc1(x)))"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IhffY-zTygwf"},"source":["# Transformer"]},{"cell_type":"code","metadata":{"id":"D1nz9UOcygwg"},"source":["class Encoder_Block(nn.Module):\n","    \"\"\" Transformer Block \"\"\"\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.attn = MultiHeadAttention(cfg)\n","        self.proj = nn.Linear(cfg.dim, cfg.dim)\n","        self.norm1 = LayerNorm(cfg)\n","        self.pwff = PositionWiseFeedForward(cfg)\n","        self.norm2 = LayerNorm(cfg)\n","        self.drop = nn.Dropout(cfg.p_drop_hidden)\n","\n","    def forward(self, x, mask):\n","        h = self.attn(x, mask)\n","        h = self.norm1(x + self.drop(self.proj(h)))\n","        h = self.norm2(h + self.drop(self.pwff(h)))\n","        return h\n","    \n","def get_attn_pad_mask(seq_q, seq_k):\n","    batch_size, len_q = seq_q.size()\n","    batch_size, len_k = seq_k.size()\n","    # eq(zero) is PAD token\n","    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n","    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k\n","    \n","def get_attn_subsequent_mask(seq):\n","    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n","    subsequent_mask = np.triu(np.ones(attn_shape), k=1)\n","    subsequent_mask = torch.tensor(subsequent_mask, device=seq.device).byte()\n","    return subsequent_mask\n","    \n","    \n","class Decoder_Block(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.self_attention = MultiHeadAttention(cfg)    # 디코더의 인풋 부분\n","        self.encoder_attention = MultiHeadAttention(cfg) # encoder로 부터 온애\n","        \n","        self.norm1 = LayerNorm(cfg)\n","        self.proj1 = nn.Linear(cfg.dim, cfg.dim)\n","        self.norm2 = LayerNorm(cfg)\n","        self.proj2 = nn.Linear(cfg.dim, cfg.dim)\n","        \n","        self.pwff = PositionWiseFeedForward(cfg)\n","        self.norm3 = LayerNorm(cfg)\n","        \n","        self.drop = nn.Dropout(cfg.p_drop_hidden)\n","        \n","    def forward(self,x , enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n","        \n","        \n","        # self-attention -> add&norm\n","        h = self.self_attention(x, dec_self_attn_mask)\n","        h = self.norm1(x + self.drop(self.proj1(h)))\n","        \n","        # encoder attention -> add&norm\n","        h2 = self.encoder_attention(enc_outputs, dec_enc_attn_mask, x_q=h)\n","        h = self.norm2(h + self.drop(self.proj2(h2))) \n","        \n","        # feedforward network\n","        h = self.norm3(h + self.drop(self.pwff(h)))\n","        \n","        return h\n","\n","class Transformer(nn.Module):\n","    \"\"\" Transformer with Self-Attentive Blocks\"\"\"\n","    def __init__(self, cfg):\n","        super().__init__()\n","        #====================encoder===========================\n","        self.encoder_embed = Embeddings(cfg)\n","        self.encoder_blocks = nn.ModuleList([Encoder_Block(cfg) for _ in range(cfg.n_layers)])\n","\n","        #====================decoder============================\n","        self.decoder_embed = Embeddings(cfg)\n","        self.decoder_blocks = nn.ModuleList([Decoder_Block(cfg) for _ in range(cfg.n_layers)])\n","        \n","        #=========================================================\n","        self.projection = nn.Linear(cfg.dim, cfg.vocab_size)\n","        \n","        \n","    def forward(self, enc_inputs, dec_inputs):\n","        #============encoder============\n","        h = self.encoder_embed(enc_inputs)\n","        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs)\n","        for block in self.encoder_blocks:\n","            h = block(h, enc_self_attn_mask)\n","            \n","        enc_outputs = h\n","        \n","        \n","        #============decoder============\n","        \n","        # self attention mask\n","        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs).float()\n","        dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_inputs).float()\n","        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)\n","\n","        # encoder attention mask\n","        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs)\n","        \n","        \n","        # embedding\n","        h = self.decoder_embed(dec_inputs)\n","        \n","        \n","        for block in self.decoder_blocks:\n","            h = block(h, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n","        #============projection==========\n","        out = self.projection(h)\n","        \n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eWK80vqMygwm","outputId":"504ad715-e0e5-4175-a3f5-b087c1b14dc0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660702123601,"user_tz":-540,"elapsed":6466,"user":{"displayName":"Kim Taesung","userId":"07470511053361482197"}}},"source":["model = Transformer(model_config)\n","out = model(sample[0],sample[0])\n","out.size()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 128, 30522])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"ARGqrCFYygwr"},"source":[""],"execution_count":null,"outputs":[]}]}