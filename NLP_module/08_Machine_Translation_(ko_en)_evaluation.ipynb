{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Translation (ko-en) - evaluation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w8ew706HC5C"
      },
      "source": [
        "# 기계 번역 모델 평가\n",
        "\n",
        "이번 실습에서는 기계 번역 모델을 평가하는 방법에 대해 살펴보겠습니다.\n",
        "\n",
        "기계 번역이란 하나의 언어로 적혀져있는 문장을 다른 언어의 문장으로 번역하는 분야를 뜻합니다.\n",
        "\n",
        "룰에 따라 번역을 하는 단순한 기계 번역부터 딥러닝 모델을 이용한 최신 모델까지 다양하게 있습니다.\n",
        "\n",
        "지난 실습에서는 이러한 기계 번역을 수행하는 딥러닝 모델 중 하나인 RNN 기반의 seq2seq 모델의 학습에 대해 살펴보았습니다.\n",
        "\n",
        "이번 실습에서는 Transformer 기반에 이미 학습이 완료된 모델을 통해 그 결과를 살펴보겠습니다.\n",
        "\n",
        "그리고 해당 모델의 성능이 얼마나 뛰어난지를 살펴보는 모델 평가에 대해 진행하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UHrrMFW0-Ef"
      },
      "source": [
        "기계 번역 모델의 평가는 기존에 살펴보았던 여러 모델들 평가와는 조금 다릅니다.\n",
        "\n",
        "기존에 보았던 문제들은 classification입니다. \n",
        "\n",
        "즉, 입력으로 들어온 데이터를 보고 미리 정한 클래스 중 가장 적합한 클래스를 선택하는 것입니다.\n",
        "\n",
        "대표적으로 감정 분석의 경우 주어진 텍스트를 보고 긍정, 부정의 클래스를 맞추는 것이지요.\n",
        "\n",
        "이런 경우 그 모델의 평가는 대체로 정확도(accuracy)로 계산합니다.\n",
        "\n",
        "모델이 내놓은 결과인 클래스와 실제 데이터의 결과인 클래스를 비교하여 얼마나 맞추었는지를 살펴보는 것이지요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3pcyC_o2Fih"
      },
      "source": [
        "\n",
        "하지만 기계 번역 모델의 경우 모델과 데이터의 결과 모두 단어의 조합인 문장입니다.\n",
        "\n",
        "그렇기에 단순히 정확도로 판단하기에는 어렵습니다.\n",
        "\n",
        "아래 예시를 살펴보겠습니다.\n",
        "\n",
        "- 입력 문장: 오늘 저는 여러분들과 만나게 되어 반갑습니다\n",
        "- 데이터 내 영어 번역 문장: Today I am glad to meet you\n",
        "- 모델의 번역 문장: It is a pleasure to meet you today\n",
        "\n",
        "두 번째 문장과 세 번째 문장 모두 첫 번째 문장에 적합한 번역 문장입니다.\n",
        "\n",
        "하지만 단순히 두 문장이 정확하게 일치하는지를 살펴보게 된다면 첫 번째 단어가 다르기에 0점을 주게 되는 문제가 발생합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bI4YDqf2SCw"
      },
      "source": [
        "이런 문제를 해결하고자 여러 방법이 제안되었습니다.\n",
        "\n",
        "그 중에서 이번 실습에서는 ROUGE(Recall-Oriented Understudy for Gisting Evaluation)에 대해 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjj7XEd3BuDy"
      },
      "source": [
        "## 학습된 기계 번역 모델 사용\n",
        "\n",
        "ROUGE에 대해 살펴보기에 앞서 먼저 학습된 번역 모델을 살펴보겠습니다.\n",
        "\n",
        "여러 기계 번역 모델이 있지만 그 중에서 한국어-영어 번역 모델을 하나 가져오겠습니다.\n",
        "\n",
        "출처: https://huggingface.co/Helsinki-NLP/opus-mt-ko-en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvdTJtt1CcRU"
      },
      "source": [
        "코드 실행에 필요한 라이브러리를 설치하고 로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tmTo5O9aHtH"
      },
      "source": [
        "!pip install torch==1.7.0\n",
        "!pip install transformers==3.5.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgnaF87tCfhj"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlUeGHEJPZeV"
      },
      "source": [
        "텍스트를 나눌 tokenizer와 학습 모델을 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pia7XebEPbS1"
      },
      "source": [
        "ko_tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ko-en\")\n",
        "\n",
        "mt_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ko-en\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0C0fY54ZDmU"
      },
      "source": [
        "불러온 모델을 가지고 번역을 진행해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH-Goaky8J5w"
      },
      "source": [
        "text1 = \"대한민국은 민주공화국이다\"\n",
        "text2 = \"대한민국의 주권은 국민에게 있고 모든 권력은 국민으로부터 나온다\"\n",
        "tokenized_text = ko_tokenizer.prepare_seq2seq_batch([text1, text2])\n",
        "\n",
        "translation = mt_model.generate(**tokenized_text)\n",
        "translated_text = ko_tokenizer.batch_decode(translation, skip_special_tokens=True)\n",
        "\n",
        "print(translated_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq7AfgBi4Tgo"
      },
      "source": [
        "결과가 나름 깔끔하게 잘 나오는 것을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZhhZRkJChKT"
      },
      "source": [
        "## ROUGE\n",
        "\n",
        "이제 이렇게 학습된 모델을 평가하도록 하겠습니다.\n",
        "\n",
        "평가 방법은 ROUGE입니다.\n",
        "\n",
        "ROUGE는 원래 텍스트 요약에 제안된 평가 방법입니다. \n",
        "\n",
        "요약은 긴 글을 짧은 문장으로 바꾸는 문제로 데이터에는 실제 정답 요약문이 있습니다. 그리고 모델은 긴 글을 입력으로 받아 짧은 요약문을 만듭니다. 그러면 ROUGE는 정답 요약문과 생성된 요약문을 비교하여 그 유사도를 계산합니다.\n",
        "\n",
        "이러한 접근법은 기계 번역에서도 유사합니다.\n",
        "\n",
        "기계 번역 역시 실제 정답 문장이 있고 모델이 번역한 문장이 있습니다. 그리고 이 둘이 얼마나 유사한지를 계산하면 됩니다.\n",
        "\n",
        "ROUGE는 이처럼 두 문장의 유사도를 계산하는 방법이라고 보시면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLVIJZaL5HjG"
      },
      "source": [
        "ROUGE 알고리즘은 기본적으로 두 문장의 단어가 겹치는 부분을 계산합니다.\n",
        "\n",
        "- 입력 문장: 오늘 저는 여러분들과 만나게 되어 반갑습니다\n",
        "- 정답 문장: Today I am glad to meet you\n",
        "- 번역 문장: It is a pleasure to meet you today\n",
        "\n",
        "위의 예시에서 정답 문장과 번역 문장을 비교하면 우리는 두 문장 내 단어가 얼마나 겹치는지를 살펴보면서 유사도를 계산할 수 있습니다.\n",
        "\n",
        "`to`, `meet`, `you` 단어 3개가 두 문장 내에 나타나는 것을 알 수 있습니다.\n",
        "\n",
        "그리고 번역 문장에서 단어의 개수는 총 8개입니다.\n",
        "\n",
        "그렇다면 8개 단어를 모델이 만들었고 그 중 3개가 정답 문장에 있는 것이니 $3/8=0.375$의 수치로 모델 성능을 평가할 수 있습니다.\n",
        "\n",
        "이렇게 계산한 값을 `precision`이라고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy9MnO6e8Dbs"
      },
      "source": [
        "하지만 이것만이 중요할까요?\n",
        "\n",
        "반대로 정답 문장에 있는 단어들을 모델이 얼마나 찾아내어 이를 생성하였는지 중요합니다.\n",
        "\n",
        "즉, 정답 문장 내 7개 단어들 중 모델은 총 3개를 만들었기에 $3/7=0.428$의 수치 역시 모델 성능을 평가할 수 있습니다.\n",
        "\n",
        "이렇게 계산한 값을 `recall`이라고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gXrCCmk8jzI"
      },
      "source": [
        "이렇게 `precision`과 `recall`은 각각 ROUGE를 통해 계산한 모델의 성능 수치입니다.\n",
        "\n",
        "이 둘을 모아서 하나의 값으로 보고 싶을 수 있습니다.\n",
        "\n",
        "그럴 때 우리는 이 둘의 조화 평균값을 구합니다.\n",
        "\n",
        "$$F = \\frac{2 \\times P \\times R}{P + R}$$\n",
        "\n",
        "$P$: `precision`, $R$: `recall`, $F$: `F score`\n",
        "\n",
        "이렇게 계산한 값을 `F score` 이라고 부릅니다.\n",
        "\n",
        "Tip) 가끔 `precision`과 `recall` 모두 0이 되는 경우가 있습니다. 즉, 두 문장에 아무것도 겹치는 단어가 없는 경우입니다. 이럴 때 `F score`를 계산해버리면 분모가 0이 되어 문제가 됩니다. 이를 해결하기 위해 아주 작은 값을 분모에 더하면 이런 문제를 방지할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWy9vxSo93XU"
      },
      "source": [
        "ROUGE는 이처럼 겹치는 단어만을 보고 모델의 성능을 평가하지 않습니다.\n",
        "\n",
        "아래와 같은 예시를 보겠습니다.\n",
        "\n",
        "- 입력 문장: 오늘 저는 여러분들과 만나게 되어 반갑습니다\n",
        "- 정답 문장: Today I am glad to meet you\n",
        "- 번역 문장1: It is a pleasure to meet you today\n",
        "- 번역 문장2: It a to today meet pleasure is you \n",
        "\n",
        "번역 문장 1과 2는 단어는 같지만 그 순서가 다릅니다.\n",
        "\n",
        "그리고 문장 2는 좋지 못한 번역 문장임을 알 수 있습니다.\n",
        "\n",
        "하지만 단어만으로 ROUGE를 계산하게 된다면 번역 문장 1과 2는 동일한 값을 가지는 문제가 있습니다.\n",
        "\n",
        "이를 해결하기 위해서는 어떻게 해야할까요?\n",
        "\n",
        "단어의 순서를 고려하는 방법 중 하나가 바로 n-gram입니다.\n",
        "\n",
        "n-gram은 주어진 n개의 단어를 하나의 단위로 묶어서 살펴보는 방법입니다.\n",
        "\n",
        "n이 1인 경우는 unigram이라 불리어 단어 하나씩 보는 경우를 뜻합니다.\n",
        "\n",
        "n이 2인 경우는 bigram이라 불리어 연속된 두 단어를 하나로 묶어 살펴봅니다.\n",
        "\n",
        "예를 들어 정답 문장의 bigram을 구하면 아래와 같습니다.\n",
        "\n",
        "- Today I\n",
        "- I am\n",
        "- am glad\n",
        "- glad to\n",
        "- to meet\n",
        "- meet you\n",
        "\n",
        "번역 문장1의 bigram을 구하면 아래와 같습니다.\n",
        "- It is\n",
        "- is a\n",
        "- a pleasure\n",
        "- pleasure to\n",
        "- to meet\n",
        "- meet you\n",
        "- you today\n",
        "\n",
        "번역 문장2의 bigram을 구하면 아래와 같습니다.\n",
        "- It a\n",
        "- a to\n",
        "- to today\n",
        "- today meet\n",
        "- meet pleasure\n",
        "- pleasure is\n",
        "- is you\n",
        "\n",
        "이렇게 bigram으로 token을 만든 후 비교해보면 정답 문장과 번역 문장1은 2개가 겹칩니다.\n",
        "\n",
        "하지만 정답 문장과 번역 문장2는 하나도 겹치는 bigram token이 없습니다. 즉, ROUGE precision, recall, F score 모두 0의 값입니다.\n",
        "\n",
        "이를 통해 번역 문장1이 번역 문장2보다는 좋은 문장임을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZazt7Nu_slb"
      },
      "source": [
        "이번 실습에서는 ROUGE를 직접 구현하도록 하겠습니다.\n",
        "\n",
        "ROUGE에는 여러 기법이 있지만 그 중 n-gram을 사용한 방법을 소개하였고 이를 구현하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QQOuUJo600a"
      },
      "source": [
        "### unigram\n",
        "\n",
        "- 문제 1. unigram을 만드는 함수를 작성해주세요.\n",
        "  - 문장(sentence)와 토크나이저(tokenizer)를 입력으로 받아 토크나이저를 이용하여 unigram을 만들어주세요.\n",
        "  - 결과는 Python의 set의 형태로 반환해주세요.\n",
        "  - 문장 내 중복으로 나타나는 단어는 한 번 나타난 것으로 취급해주세요.\n",
        "  - `ngram` 함수에서 `n`이 1인 경우와 동일해야합니다. 하지만 해당 함수를 이 함수 내에서 사용하지 마세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYucrg5wCjyA"
      },
      "source": [
        "def unigram(sentence, tokenizer):\n",
        "    results_unigram = set()\n",
        "    # <ToDo>: sentence에서 unigram을 만드세요.\n",
        "    return results_unigram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G2gx5ot61ZK"
      },
      "source": [
        "### bigram\n",
        "\n",
        "- 문제 2. bigram을 만드는 함수를 작성해주세요.\n",
        "  - 문장(sentence)와 토크나이저(tokenizer)를 입력으로 받아 토크나이저를 이용하여 bigram을 만들어주세요.\n",
        "  - 결과는 Python의 set의 형태로 반환해주세요.\n",
        "  - 중복으로 나타나는 bigram token은 한 번 나타난 것으로 취급해주세요.\n",
        "  - `ngram` 함수에서 `n`이 2인 경우와 동일해야합니다. 하지만 해당 함수를 이 함수 내에서 사용하지 마세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwSl-eHT61tO"
      },
      "source": [
        "def bigram(sentence, tokenizer):\n",
        "    results_bigram = set()\n",
        "    # <ToDo>: sentence에서 bigram을 만드세요.\n",
        "    return results_bigram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_q0LEj663eO"
      },
      "source": [
        "### n-gram\n",
        "\n",
        "- 문제 3. n-gram을 만드는 함수를 작성해주세요.\n",
        "  - 문장(sentence)와 토크나이저(tokenizer)를 입력으로 받아 토크나이저를 이용하여 n-gram을 만들어주세요.\n",
        "  - 결과는 Python의 set의 형태로 반환해주세요.\n",
        "  - 중복으로 나타나는 n-gram token은 한 번 나타난 것으로 취급해주세요.\n",
        "  - n이 1일 때와 2일 때는 각각 `unigram`과 `bigram` 함수와 동일한 결과를 출력해야합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQs5KQAZ63vV"
      },
      "source": [
        "def ngram(sentence, tokenizer, n):\n",
        "    results_ngram = set()\n",
        "    # <ToDo>: sentence에서 ngram을 만드세요.\n",
        "    return results_ngram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHGyTyvL66i6"
      },
      "source": [
        "### ROUGE\n",
        "\n",
        "- 문제 4. ROUGE를 계산하는 함수를 작성해주세요.\n",
        "  - 정답 문장(original_sentence)와 번역 문장(translated_sentence)의 차이를 ROUGE로 계산해주세요.\n",
        "  - 토크나이저(tokenizer)를 통해 단어 토큰을 만들고 n의 크기에 따라 n-gram 토큰을 만드세요.\n",
        "  - 결과는 ROUGE의 precision, recall, F score 세 개를 반환해주세요.\n",
        "  - 가끔 입력 문장이 빈 문장(길이가 0인 문장)일 수 있습니다. 이 때 계산 시 분모가 0이 되는 값이 생길 수 있습니다. 이런 경우 그 값을 0으로 만들어주세요.\n",
        "  - F score 계산 시 분모가 0이 되는 경우를 주의해주세요. (힌트: small_num 값 사용)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD4nnH7d66wM"
      },
      "source": [
        "def rouge(original_sentence, translated_sentence, n, tokenizer, small_num=1e-8):\n",
        "    # 입력 문장들을 전부 소문자로 바꿉니다.\n",
        "    original_sentence = original_sentence.lower()\n",
        "    translated_sentence = translated_sentence.lower()\n",
        "\n",
        "    # n의 크기에 따라 함수를 호출합니다.\n",
        "    if n <= 0:\n",
        "        print(\"n은 0보다 커야합니다.\")\n",
        "        return None\n",
        "    elif 1 == n:\n",
        "        original_grams = unigram(original_sentence, tokenizer)\n",
        "        translated_grams = unigram(translated_sentence, tokenizer)\n",
        "    elif 2 == n:\n",
        "        original_grams = bigram(original_sentence, tokenizer)\n",
        "        translated_grams = bigram(translated_sentence, tokenizer)\n",
        "    else:\n",
        "        original_grams = ngram(original_sentence, tokenizer, n)\n",
        "        translated_grams = ngram(translated_sentence, tokenizer, n)\n",
        "\n",
        "    # 찾아낸 gram들의 개수를 셉니다.\n",
        "    original_count = len(original_grams)\n",
        "    translated_count = len(translated_grams)\n",
        "\n",
        "    # <ToDo>: 중첩되는 ngrams을 구하세요.\n",
        "    overlapping_ngrams = None\n",
        "    overlapping_count = len(overlapping_ngrams)\n",
        "\n",
        "    # <ToDo>: precision을 구하세요.\n",
        "    precision = None\n",
        "\n",
        "    # <ToDo>: recall을 구하세요.\n",
        "    recall = None\n",
        "\n",
        "    # <ToDo>: F score를 구하세요.\n",
        "    f_score = None\n",
        "\n",
        "    return precision, recall, f_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUKAEB_E68dT"
      },
      "source": [
        "### 실행 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhGMFmpV686S"
      },
      "source": [
        "# tokenizer는 nltk를 사용합니다.\n",
        "en_tokenizer = nltk.word_tokenize\n",
        "\n",
        "# 예시 문장\n",
        "original_sen = \"Today I am glad to meet you\"\n",
        "translated_sen1 = \"It is a pleasure to meet you today\"\n",
        "translated_sen2 = \"It a to today meet pleasure is you\"\n",
        "\n",
        "# 정답 문장과 번역 문장1을 ROUGE로 비교합니다.\n",
        "print(\"Original: {}\".format(original_sen))\n",
        "print(\"Translated: {}\".format(translated_sen1))\n",
        "\n",
        "p, r, f = rouge(original_sen, translated_sen1, 1, en_tokenizer)\n",
        "print(\"ROUGE unigram: Precision: {:.4f}, Recall: {:.4f}, F score:{:.4f}\".format(p, r, f))\n",
        "\n",
        "p, r, f = rouge(original_sen, translated_sen1, 2, en_tokenizer)\n",
        "print(\"ROUGE bigram: Precision: {:.4f}, Recall: {:.4f}, F score:{:.4f}\".format(p, r, f))\n",
        "\n",
        "p, r, f = rouge(original_sen, translated_sen1, 3, en_tokenizer)\n",
        "print(\"ROUGE trigram(n=3): Precision: {:.4f}, Recall: {:.4f}, F score:{:.4f}\".format(p, r, f))\n",
        "print()\n",
        "\n",
        "# 정답 문장과 번역 문장2를 ROUGE로 비교합니다.\n",
        "print(\"Original: {}\".format(original_sen))\n",
        "print(\"Translated: {}\".format(translated_sen2))\n",
        "\n",
        "p, r, f = rouge(original_sen, translated_sen2, 1, en_tokenizer)\n",
        "print(\"ROUGE unigram: Precision: {:.4f}, Recall: {:.4f}, F score:{:.4f}\".format(p, r, f))\n",
        "\n",
        "p, r, f = rouge(original_sen, translated_sen2, 2, en_tokenizer)\n",
        "print(\"ROUGE bigram: Precision: {:.4f}, Recall: {:.4f}, F score:{:.4f}\".format(p, r, f))\n",
        "\n",
        "p, r, f = rouge(original_sen, translated_sen2, 3, en_tokenizer)\n",
        "print(\"ROUGE trigram(n=3): Precision: {:.4f}, Recall: {:.4f}, F score:{:.4f}\".format(p, r, f))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSDlc7hgHyYQ"
      },
      "source": [
        "ROUGE에도 한계점이 있다는 것을 알 수 있습니다. 대표적으로 'pleasure'와 'glad'는 비슷한 뜻을 지니고 있지만 ROUGE는 이 차이를 무조건 다르다고만 얘기하고 있기 때문입니다. 이러한 단점을 극복하고자 여러 방법이 제안되고 있습니다. 이처럼 NLP 모델의 평가는 현재 많은 연구가 활발하게 이루어지고 있는 연구 분야입니다."
      ]
    }
  ]
}