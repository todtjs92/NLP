{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b73820-2d13-4742-84ab-4e8b53c7e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# MNIST 데이터셋 로드\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 데이터를 정규화\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # 매 epoch마다 섞음. \n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 모델 클래스 정의\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 500),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(500),\n",
    "            nn.Linear(500, 400),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(400),\n",
    "            nn.Linear(400, 300),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(300),\n",
    "            nn.Linear(300, 200),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.Linear(200, 100),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.Linear(50, output_size),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)  # Flatten the image\n",
    "        return self.layers(x)\n",
    "\n",
    "# 모델, 손실 함수, 최적화 방법 설정\n",
    "model = ImageClassifier(28*28, 10)  # MNIST 이미지의 크기는 28x28, 클래스는 10개\n",
    "criterion = nn.NLLLoss()  # Negative Log Likelihood Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305df791-af88-4f28-95cf-832c011dff28",
   "metadata": {},
   "source": [
    "### dataloader를 사용하려면? -> Dataset을 먼저 구현해줘야함 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d52b0bed-b42f-40e7-9de0-85c3df3ed3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3edc9016-b756-41fe-8d04-1cea1eba7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dataset 클래스 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # 데이터셋 초기화\n",
    "        # 임의의 데이터와 레이블을 생성\n",
    "        self.data = torch.randn(100, 2)  # 100개의 데이터 포인트, 각 포인트는 2차원\n",
    "        self.labels = torch.randint(0, 2, (100,))  # 0 또는 1의 레이블을 가진 100개의 데이터 포인트\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 총 데이터 수\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 인덱스(idx)에 해당하는 데이터와 레이블을 반환\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# 2. 데이터셋 인스턴스 생성\n",
    "custom_dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7516227b-e55c-4e3b-be67-9d35e87bbdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d3a03b-1be5-4fc1-89d4-4b98bb2d5fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.1338,  0.1037]), tensor(1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1f24e-b43f-4f71-9948-a845910016f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74408a-d406-40b5-beab-7172cc41ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 루프\n",
    "def train(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}')\n",
    "\n",
    "# 모델 학습 실행\n",
    "train(model, train_loader, criterion, optimizer)\n",
    "\n",
    "# 테스트 함수 (필요 시 사용)\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            output = model(images)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    print(f'Accuracy: {correct / len(test_loader.dataset) * 100:.2f}%')\n",
    "\n",
    "# 모델 테스트 실행\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a07f5-2d83-44e9-a9cb-557c03ee1a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
