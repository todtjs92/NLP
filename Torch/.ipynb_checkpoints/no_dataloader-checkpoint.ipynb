{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74084387-2cb6-4d8b-b01e-b2529d310c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from model import ImageClassifier\n",
    "from trainer import Trainer\n",
    "from utils import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8934774-317f-4e1a-b129-2c1c77366338",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccce3d74-0d15-44a8-b94a-5b89dde862f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc0b7fe6-6c0a-437d-80cf-d307f64de8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(is_train=True, flatten=True):\n",
    "    from torchvision import datasets, transforms\n",
    "\n",
    "    dataset = datasets.MNIST(\n",
    "        '../data', train=is_train, download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ]),\n",
    "    )\n",
    "\n",
    "    x = dataset.data.float() / 255. # dataset이라는 클래스 받아오고 텐서로 바꿔놓음. 값이 int로 되있어가지구 float형으로 바꿔줘야함 .\n",
    "    y = dataset.targets #  target에는 int형으로 들어가있음, 물론 텐서로 ,.\n",
    "\n",
    "    if flatten:\n",
    "        x = x.view(x.size(0), -1) # view 쓰면 60000, 28 ,28 에서 60000, 784 로 맞춰줌.\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea71ae0e-1450-46a0-b976-69ccea2214f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST(\n",
    "        '../data', train=True, download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41452d1d-912d-49dc-8b91-e53e06f1bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.data.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92bf5e26-5ed2-48bf-8cf0-0c4158dea809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99011e01-a627-4242-ad38-10881839bbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7543f164-13a8-45bd-a5a9-821e9d09ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af619dbb-e219-43b1-aba6-49bead85ea02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b0e9987-f1f0-4a46-a72b-ad8bc9c74e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "029eb403-ec7a-449a-80ac-5246b43a7706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1ffa180-dadf-4a8b-9e3a-5f2968b07214",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2056e86-ee76-4a2d-9f61-fb313b714d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randperm(x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bc18a2d-7494-420c-94c9-f9d3c45aea42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2981, 20321, 51672,  ..., 52457, 21072, 51286])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c8e1f16-7283-40c3-9f83-bbded52a1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnt = int(x.size(0) * 0.85)\n",
    "valid_cnt = x.size(0) - train_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87addd7b-f934-4feb-94cb-bd0fcfc0f399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c607c0f-3bf0-4cd5-a273-7010b09c0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.index_select(\n",
    "        x,\n",
    "        dim=0,\n",
    "        index=indices\n",
    "    ).to(device).split([train_cnt, valid_cnt], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "628d4fde-0ccd-40ac-8b31-de54d3025292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a99a3c7-a3ff-464d-8545-6fd9084f9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.index_select(\n",
    "        y,\n",
    "        dim=0,\n",
    "        index=indices\n",
    "    ).to(device).split([train_cnt, valid_cnt], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f71ad02-eed7-46b5-a43b-730f07fcb0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 0, 1,  ..., 8, 7, 3]), tensor([3, 1, 4,  ..., 4, 9, 0]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a138326-265a-4961-9a01-6d809ef8e673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: torch.Size([51000, 784]) torch.Size([51000])\n",
      "Valid: torch.Size([9000, 784]) torch.Size([9000])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", x[0].shape, y[0].shape)\n",
    "print(\"Valid:\", x[1].shape, y[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06c05593-b31c-42ac-821f-211f5cdfb28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ImageClassifier(nn.Module): # nn.module 상속받고\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 output_size):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(  # Layer 정의\n",
    "            nn.Linear(input_size, 500),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(500),\n",
    "            nn.Linear(500, 400),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(400),\n",
    "            nn.Linear(400, 300),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(300),\n",
    "            nn.Linear(300, 200),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.Linear(200, 100),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.Linear(50, output_size), # 마지막에 output_size 까지 넣어주고\n",
    "            nn.LogSoftmax(dim=-1),  # 마지막 원소에 대해서 소프트맥스적용 , 0~1사이값으로 바꿔줌.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # |x| = (batch_size, input_size)\n",
    "\n",
    "        y = self.layers(x)\n",
    "        # |y| = (batch_size, output_size)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81f0201a-79ba-4839-b0b0-263e55313961",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassifier(28**2, 10).to(device) # 모델 정의해주고\n",
    "optimizer = optim.Adam(model.parameters()) # 옵티마이저\n",
    "crit = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83645eb5-4e0f-419e-a9de-cc111fbe380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4148e9d-a993-48e1-b08d-86f2e0d1a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer():\n",
    "\n",
    "    def __init__(self, model, optimizer, crit):\n",
    "        self.model = model        # 모델을 다시 들고오는 방식으로 ,\n",
    "        self.optimizer = optimizer\n",
    "        self.crit = crit\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def _train(self, x, y, config):\n",
    "        self.model.train()\n",
    "\n",
    "        # Shuffle before begin.\n",
    "        indices = torch.randperm(x.size(0), device=x.device)\n",
    "        x = torch.index_select(x, dim=0, index=indices).split(batch_size, dim=0) # split쓰면 알아서 쪼개줌.\n",
    "        y = torch.index_select(y, dim=0, index=indices).split(batch_size, dim=0)\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for i, (x_i, y_i) in enumerate(zip(x, y)):\n",
    "            y_hat_i = self.model(x_i)   # instance한 모델에 스플릿한데이터 넣어주기\n",
    "            loss_i = self.crit(y_hat_i, y_i.squeeze())\n",
    "            '''\n",
    "            (A x B x 1 x C x 1) 형태의 텐서에서 차원이 1인 부분을 제거하여 (A x B x C) 형태로  [] 이런것들 없애줌.\n",
    "            '''\n",
    "\n",
    "            # Initialize the gradients of the model.\n",
    "            # 로스 게산하고 조정 파라미터들\n",
    "            self.optimizer.zero_grad()\n",
    "            loss_i.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if config.verbose >= 2:\n",
    "                print(\"Train Iteration(%d/%d): loss=%.4e\" % (i + 1, len(x), float(loss_i)))\n",
    "\n",
    "            # Don't forget to detach to prevent memory leak.\n",
    "            total_loss += float(loss_i)\n",
    "\n",
    "        return total_loss / len(x)\n",
    "\n",
    "    def _validate(self, x, y, config):\n",
    "        # Turn evaluation mode on.\n",
    "        self.model.eval()\n",
    "\n",
    "        # Turn on the no_grad mode to make more efficintly.\n",
    "        with torch.no_grad():\n",
    "            # Shuffle before begin.\n",
    "            indices = torch.randperm(x.size(0), device=x.device)\n",
    "            x = torch.index_select(x, dim=0, index=indices).split(batch_size, dim=0)\n",
    "            y = torch.index_select(y, dim=0, index=indices).split(batch_size, dim=0)\n",
    "\n",
    "            total_loss = 0\n",
    "\n",
    "            for i, (x_i, y_i) in enumerate(zip(x, y)):\n",
    "                y_hat_i = self.model(x_i)\n",
    "                loss_i = self.crit(y_hat_i, y_i.squeeze())\n",
    "\n",
    "                if config.verbose >= 2:\n",
    "                    print(\"Valid Iteration(%d/%d): loss=%.4e\" % (i + 1, len(x), float(loss_i)))\n",
    "\n",
    "                total_loss += float(loss_i)\n",
    "\n",
    "            return total_loss / len(x)\n",
    "\n",
    "    def train(self, train_data, valid_data, config):\n",
    "        lowest_loss = np.inf\n",
    "        best_model = None\n",
    "\n",
    "        for epoch_index in range(n_epochs):\n",
    "            train_loss = self._train(train_data[0], train_data[1], config)\n",
    "            valid_loss = self._validate(valid_data[0], valid_data[1], config)\n",
    "\n",
    "            # You must use deep copy to take a snapshot of current best weights.\n",
    "            if valid_loss <= lowest_loss:\n",
    "                lowest_loss = valid_loss\n",
    "                best_model = deepcopy(self.model.state_dict()) # valid기준 로스가 젤 낮았던걸 딥카피해둠 파라미터들\n",
    "\n",
    "            print(\"Epoch(%d/%d): train_loss=%.4e  valid_loss=%.4e  lowest_loss=%.4e\" % (\n",
    "                epoch_index + 1,\n",
    "                n_epochs,\n",
    "                train_loss,\n",
    "                valid_loss,\n",
    "                lowest_loss,\n",
    "            ))\n",
    "\n",
    "        # Restore to best model.\n",
    "        self.model.load_state_dict(best_model) # 학습 끝나고 젤 좋았떤걸 이렇게 불러와서 쓸수있꾼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e4ffc7a-ba6b-4c24-af1f-c8171aa8ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, optimizer, crit)\n",
    "trainer.train((x[0], y[0]), (x[1], y[1]), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cad2fc38-c2c7-47e7-a416-3dd98b902a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_loss = np.inf\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a01bb612-d92c-4e9b-8d60-5b5a9e87201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (x[0], y[0])\n",
    "valid_data = (x[1], y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0081eed-fd3f-488e-babc-d0234de2fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[0]\n",
    "y = y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f507803c-e39c-4dd0-a543-a4649ba4c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randperm(x.size(0), device=x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1023fd5a-c74a-4006-975d-21071a5ccbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randperm(x.size(0), device=x.device)\n",
    "x = torch.index_select(x, dim=0, index=indices).split(batch_size, dim=0) # split쓰면 알아서 쪼개줌.\n",
    "y = torch.index_select(y, dim=0, index=indices).split(batch_size, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87738ad1-9446-4116-ab4b-bc08c36f3d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1594"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd5d1739-67e5-40d0-9fd8-e3bbdde15890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 784])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f160e5-f439-4be8-8a9e-fb643e2e8e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c491f1b-72b4-4cbc-aaec-94ffe512b547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb9d51-239f-47cf-8744-8eea8d371f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
